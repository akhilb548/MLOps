{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "## **Business Context**\n",
    "\"Visit with Us,\" a leading travel company, is revolutionizing the tourism industry by leveraging data-driven strategies to optimize operations and customer engagement. While introducing a new package offering, such as the Wellness Tourism Package, the company faces challenges in targeting the right customers efficiently. The manual approach to identifying potential customers is inconsistent, time-consuming, and prone to errors, leading to missed opportunities and suboptimal campaign performance.\n",
    "\n",
    "To address these issues, the company aims to implement a scalable and automated system that integrates customer data, predicts potential buyers, and enhances decision-making for marketing strategies. By utilizing an MLOps pipeline, the company seeks to achieve seamless integration of data preprocessing, model development, deployment, and CI/CD practices for continuous improvement. This system will ensure efficient targeting of customers, timely updates to the predictive model, and adaptation to evolving customer behaviors, ultimately driving growth and customer satisfaction.\n",
    "\n",
    "## **Objective**\n",
    "As an MLOps Engineer at \"Visit with Us,\" your responsibility is to design and deploy an MLOps pipeline on GitHub to automate the end-to-end workflow for predicting customer purchases. The primary objective is to build a model that predicts whether a customer will purchase the newly introduced Wellness Tourism Package before contacting them. The pipeline will include data cleaning, preprocessing, transformation, model building, training, evaluation, and deployment, ensuring consistent performance and scalability. By leveraging GitHub Actions for CI/CD integration, the system will enable automated updates, streamline model deployment, and improve operational efficiency. This robust predictive solution will empower policymakers to make data-driven decisions, enhance marketing strategies, and effectively target potential customers, thereby driving customer acquisition and business growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Description**\n",
    "The dataset contains customer and interaction data that serve as key attributes for predicting the likelihood of purchasing the Wellness Tourism Package. The detailed attributes are:\n",
    "\n",
    "\n",
    "\n",
    "**Customer Details**\n",
    "\n",
    "- **CustomerID:** Unique identifier for each customer.\n",
    "\n",
    "- **ProdTaken:** Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
    "\n",
    "- **Age:** Age of the customer.\n",
    "\n",
    "- **TypeofContact:** The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
    "\n",
    "- **CityTier:** The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
    "\n",
    "- **Occupation:** Customer's occupation (e.g., Salaried, Freelancer).\n",
    "\n",
    "- **Gender:** Gender of the customer (Male, Female).\n",
    "\n",
    "- **NumberOfPersonVisiting:** Total number of people accompanying the customer on the trip.\n",
    "\n",
    "- **PreferredPropertyStar:** Preferred hotel rating by the customer.\n",
    "\n",
    "- **MaritalStatus:** Marital status of the customer (Single, Married, Divorced).\n",
    "\n",
    "- **NumberOfTrips:** Average number of trips the customer takes annually.\n",
    "\n",
    "- **Passport:** Whether the customer holds a valid passport (0: No, 1: Yes).\n",
    "\n",
    "- **OwnCar:** Whether the customer owns a car (0: No, 1: Yes).\n",
    "\n",
    "- **NumberOfChildrenVisiting:** Number of children below age 5 accompanying the customer.\n",
    "\n",
    "- **Designation:** Customer's designation in their current organization.\n",
    "\n",
    "- **MonthlyIncome:** Gross monthly income of the customer.\n",
    "\n",
    "\n",
    "\n",
    "**Customer Interaction Data**\n",
    "\n",
    "- **PitchSatisfactionScore:** Score indicating the customer's satisfaction with the sales pitch.\n",
    "\n",
    "- **ProductPitched:** The type of product pitched to the customer.\n",
    "\n",
    "- **NumberOfFollowups:** Total number of follow-ups by the salesperson after the sales pitch.-\n",
    "\n",
    "- **DurationOfPitch:** Duration of the sales pitch delivered to the customer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* Create a GitHub repo\n",
    "\n",
    "    - Go to ***GitHub Profile***\n",
    "\n",
    "    - Click on ***Your repositories*** then select ***New***\n",
    "\n",
    "      - Repository Name: ***MLOps***\n",
    "\n",
    "      - Check the box ***README.md*** file\n",
    "\n",
    "      - Click on ***Create repository***\n",
    "\n",
    "\n",
    "\n",
    "* Adding Hugging Face space secrets to GitHub Actions to execute the workflow\n",
    "\n",
    "  1. Go to Hugging Face ***Profile***\n",
    "\n",
    "  2. Navigate to ***Access Token***\n",
    "\n",
    "  3. Create a ***New token***\n",
    "\n",
    "      - Token type ***Write***\n",
    "\n",
    "      - Token Name ***MLOps***\n",
    "\n",
    "      - Click on ***Create Token***\n",
    "\n",
    "      - Copy the generated Token\n",
    "\n",
    "  4. Now, go to GitHub repo\n",
    "\n",
    "      - Click on ***Settings***\n",
    "\n",
    "      - Navigate to ***Secrets and Variables***\n",
    "\n",
    "      - Click on ***Actions***\n",
    "\n",
    "      - Add a ***Repository secerts***\n",
    "\n",
    "        - Name ***HF_TOKEN***\n",
    "\n",
    "        - Secret: ***Paste the token created from the hugging face access tokens***\n",
    "\n",
    "        - Click on ***Add secret***\n",
    "\n",
    "\n",
    "\n",
    "* Create a Hugging Face space\n",
    "\n",
    "    - Go to **Hugging Face**\n",
    "\n",
    "    - Open your **Profile**\n",
    "\n",
    "    - Click on **New Space**\n",
    "\n",
    "      - Under the space creation, enter the below details\n",
    "\n",
    "        - Space name: **tourism-package-prediction**\n",
    "\n",
    "    (If you were trying with different names, be cautious when using a underscore `_` in space names, such as `frontend_space`, as it can cause exceptions when accessing the API URL. Always use an hyphen `-` instead, like `frontend-space`.)\n",
    "\n",
    "        - Select the space SDK: **Docker**\n",
    "\n",
    "        - Choose a Docker template: **Streamlit**\n",
    "\n",
    "        - Click on **Create Space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a master folder to keep all files created when executing the below code cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"tourism_project\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "## Data Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tourism_project/data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the **data** folder created after executing the above cell, please upload the **tourism.csv** in to the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a folder for storing the model building files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tourism_project/model_building\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/model_building/data_register.py\n",
    "\n",
    "from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "repo_id = \"<-----Hugging Face User ID ----->/tourism-package-prediction-data\"\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "# Initialize API client\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "# Step 1: Check if the space exists\n",
    "try:\n",
    "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "    print(f\"Space '{repo_id}' already exists. Using it.\")\n",
    "except RepositoryNotFoundError:\n",
    "    print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
    "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
    "    print(f\"Space '{repo_id}' created.\")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"tourism_project/data\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/model_building/prep.py\n",
    "\n",
    "# for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for creating a folder\n",
    "import os\n",
    "# for data preprocessing and pipeline creation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# for hugging face space authentication to upload files\n",
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "# Define constants for the dataset and output paths\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "DATASET_PATH = \"hf://datasets/<-----Hugging Face User ID ----->/tourism-package-prediction-data/tourism.csv\"\n",
    "tourism_dataset = pd.read_csv(DATASET_PATH)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "if 'Unnamed: 0' in tourism_dataset.columns:\n",
    "    tourism_dataset = tourism_dataset.drop('Unnamed: 0', axis=1)\n",
    "if 'CustomerID' in tourism_dataset.columns:\n",
    "    tourism_dataset = tourism_dataset.drop('CustomerID', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "# Fill numerical missing values with median\n",
    "numerical_cols = tourism_dataset.select_dtypes(include=[np.number]).columns\n",
    "for col in numerical_cols:\n",
    "    if tourism_dataset[col].isnull().sum() > 0:\n",
    "        tourism_dataset[col].fillna(tourism_dataset[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical missing values with mode\n",
    "categorical_cols = tourism_dataset.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if tourism_dataset[col].isnull().sum() > 0:\n",
    "        tourism_dataset[col].fillna(tourism_dataset[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    tourism_dataset[col] = le.fit_transform(tourism_dataset[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define the target variable for the classification task\n",
    "target = 'ProdTaken'\n",
    "\n",
    "# Define predictor matrix (X) and target variable (y)\n",
    "X = tourism_dataset.drop(target, axis=1)\n",
    "y = tourism_dataset[target]\n",
    "\n",
    "# Split dataset into train and test\n",
    "# Split the dataset into training and test sets\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y,              # Predictors (X) and target variable (y)\n",
    "    test_size=0.2,     # 20% of the data is reserved for testing\n",
    "    random_state=42,   # Ensures reproducibility by setting a fixed random seed\n",
    "    stratify=y         # Stratify to maintain class distribution\n",
    ")\n",
    "\n",
    "Xtrain.to_csv(\"Xtrain.csv\", index=False)\n",
    "Xtest.to_csv(\"Xtest.csv\", index=False)\n",
    "ytrain.to_csv(\"ytrain.csv\", index=False)\n",
    "ytest.to_csv(\"ytest.csv\", index=False)\n",
    "\n",
    "files = [\"Xtrain.csv\", \"Xtest.csv\", \"ytrain.csv\", \"ytest.csv\"]\n",
    "\n",
    "for file_path in files:\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=file_path,\n",
    "        path_in_repo=file_path.split(\"/\")[-1],  # just the filename\n",
    "        repo_id=\"<-----Hugging Face User ID ----->/tourism-package-prediction-data\",\n",
    "        repo_type=\"dataset\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "### Experimentation and Tracking (Development Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow==3.0.1 pyngrok==7.2.12 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the ngrok authorization token, please go to this [link](https://dashboard.ngrok.com/authtokens), generate a new token, copy it, and paste it in the designated code line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "import subprocess\n",
    "import mlflow\n",
    "\n",
    "# Set your auth token here (replace with your actual token)\n",
    "ngrok.set_auth_token(\"<-----Ngrok Authentication Token ----->\")\n",
    "\n",
    "# Start MLflow UI on port 5000\n",
    "process = subprocess.Popen([\"mlflow\", \"ui\", \"--port\", \"5000\"])\n",
    "\n",
    "# Create public tunnel\n",
    "public_url = ngrok.connect(5000).public_url\n",
    "print(\"MLflow UI is available at:\", public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tracking URL for MLflow\n",
    "mlflow.set_tracking_uri(public_url)\n",
    "\n",
    "# Set the name for the experiment\n",
    "mlflow.set_experiment(\"Tourism_Package_Prediction_Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for creating a folder\n",
    "import os\n",
    "# for data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# for model training, tuning, and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# for model serialization\n",
    "import joblib\n",
    "\n",
    "tourism_dataset = pd.read_csv(\"tourism_project/data/tourism.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Remove unnecessary columns\n",
    "if 'Unnamed: 0' in tourism_dataset.columns:\n",
    "    tourism_dataset = tourism_dataset.drop('Unnamed: 0', axis=1)\n",
    "if 'CustomerID' in tourism_dataset.columns:\n",
    "    tourism_dataset = tourism_dataset.drop('CustomerID', axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "numerical_cols = tourism_dataset.select_dtypes(include=[np.number]).columns\n",
    "for col in numerical_cols:\n",
    "    if tourism_dataset[col].isnull().sum() > 0:\n",
    "        tourism_dataset[col].fillna(tourism_dataset[col].median(), inplace=True)\n",
    "\n",
    "categorical_cols = tourism_dataset.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if tourism_dataset[col].isnull().sum() > 0:\n",
    "        tourism_dataset[col].fillna(tourism_dataset[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    tourism_dataset[col] = le.fit_transform(tourism_dataset[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define the target variable for the classification task\n",
    "target = 'ProdTaken'\n",
    "\n",
    "# Define predictor matrix (X) and target variable (y)\n",
    "X = tourism_dataset.drop(target, axis=1)\n",
    "y = tourism_dataset[target]\n",
    "\n",
    "# Split dataset into train and test\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Train multiple models with MLflow tracking\n",
    "models = {\n",
    "    'Decision_Tree': DecisionTreeClassifier(max_depth=10, min_samples_split=20, min_samples_leaf=10, random_state=42),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_split=10, min_samples_leaf=5, random_state=42, n_jobs=-1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'Gradient_Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, min_child_weight=3, subsample=0.8, colsample_bytree=0.8, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train model\n",
    "        model.fit(Xtrain, ytrain)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(Xtest)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(ytest, y_pred),\n",
    "            'precision': precision_score(ytest, y_pred, average='weighted'),\n",
    "            'recall': recall_score(ytest, y_pred, average='weighted'),\n",
    "            'f1_score': f1_score(ytest, y_pred, average='weighted'),\n",
    "            'roc_auc': roc_auc_score(ytest, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        results[model_name] = {'model': model, 'metrics': metrics}\n",
    "        print(f\"{model_name} - Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see, all the experiments conducted during model training are being logged by MLflow.\n",
    "\n",
    "- Upon clicking the links in the output of the above code cell, we can check the tracking on MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tested the experimentation tracking with MLflow in a development environment, let's convert this to the required script for production environment usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation and Tracking (Production Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/model_building/train.py\n",
    "\n",
    "# for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for model training, tuning, and evaluation\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "# for model serialization\n",
    "import joblib\n",
    "# for creating a folder\n",
    "import os\n",
    "# for hugging face space authentication to upload files\n",
    "from huggingface_hub import login, HfApi, create_repo\n",
    "from huggingface_hub.utils import RepositoryNotFoundError, HfHubHTTPError\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"tourism-package-prediction-experiment\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "Xtrain_path = \"hf://datasets/<-----Hugging Face User ID ----->/tourism-package-prediction-data/Xtrain.csv\"\n",
    "Xtest_path = \"hf://datasets/<-----Hugging Face User ID ----->/tourism-package-prediction-data/Xtest.csv\"\n",
    "ytrain_path = \"hf://datasets/<-----Hugging Face User ID ----->/tourism-package-prediction-data/ytrain.csv\"\n",
    "ytest_path = \"hf://datasets/<-----Hugging Face User ID ----->/tourism-package-prediction-data/ytest.csv\"\n",
    "\n",
    "Xtrain = pd.read_csv(Xtrain_path)\n",
    "Xtest = pd.read_csv(Xtest_path)\n",
    "ytrain = pd.read_csv(ytrain_path)\n",
    "ytest = pd.read_csv(ytest_path)\n",
    "\n",
    "# Train multiple models with MLflow tracking\n",
    "models = {\n",
    "    'Decision_Tree': DecisionTreeClassifier(max_depth=10, min_samples_split=20, min_samples_leaf=10, random_state=42),\n",
    "    'Random_Forest': RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_split=10, min_samples_leaf=5, random_state=42, n_jobs=-1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "    'Gradient_Boosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, min_child_weight=3, subsample=0.8, colsample_bytree=0.8, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "best_f1_score = 0\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Train model\n",
    "        model.fit(Xtrain, ytrain.values.ravel())\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(Xtest)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(ytest, y_pred),\n",
    "            'precision': precision_score(ytest, y_pred, average='weighted'),\n",
    "            'recall': recall_score(ytest, y_pred, average='weighted'),\n",
    "            'f1_score': f1_score(ytest, y_pred, average='weighted'),\n",
    "            'roc_auc': roc_auc_score(ytest, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        results[model_name] = {'model': model, 'metrics': metrics}\n",
    "        print(f\"{model_name} - Accuracy: {metrics['accuracy']:.4f}, F1-Score: {metrics['f1_score']:.4f}\")\n",
    "        \n",
    "        # Track best model based on F1-score\n",
    "        if metrics['f1_score'] > best_f1_score:\n",
    "            best_f1_score = metrics['f1_score']\n",
    "            best_model_name = model_name\n",
    "            best_model = model\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} with F1-Score: {best_f1_score:.4f}\")\n",
    "\n",
    "# Save the best model locally\n",
    "model_path = \"best_tourism_model_v1.joblib\"\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Log the model artifact\n",
    "print(f\"Model saved as artifact at: {model_path}\")\n",
    "\n",
    "# Upload to Hugging Face\n",
    "repo_id = \"<-----Hugging Face User ID ----->/tourism-package-prediction-model\"\n",
    "repo_type = \"model\"\n",
    "\n",
    "# Step 1: Check if the space exists\n",
    "try:\n",
    "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "    print(f\"Space '{repo_id}' already exists. Using it.\")\n",
    "except RepositoryNotFoundError:\n",
    "    print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
    "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
    "    print(f\"Space '{repo_id}' created.\")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"best_tourism_model_v1.joblib\",\n",
    "    path_in_repo=\"best_tourism_model_v1.joblib\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment\n",
    "## Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tourism_project/deployment\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/deployment/Dockerfile\n",
    "\n",
    "# Use a minimal base image with Python 3.9 installed\n",
    "FROM python:3.9\n",
    "\n",
    "# Set the working directory inside the container to /app\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy all files from the current directory on the host to the container's /app directory\n",
    "COPY . .\n",
    "\n",
    "# Install Python dependencies listed in requirements.txt\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "RUN useradd -m -u 1000 user\n",
    "USER user\n",
    "ENV HOME=/home/user \\\n",
    "\tPATH=/home/user/.local/bin:$PATH\n",
    "\n",
    "WORKDIR $HOME/app\n",
    "\n",
    "COPY --chown=user . $HOME/app\n",
    "\n",
    "# Define the command to run the Streamlit app on port \"8501\" and make it accessible externally\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/deployment/app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from huggingface_hub import hf_hub_download\n",
    "import joblib\n",
    "\n",
    "# Download the model from the Model Hub\n",
    "model_path = hf_hub_download(repo_id=\"<-----Hugging Face User ID ----->/tourism-package-prediction-model\", filename=\"best_tourism_model_v1.joblib\")\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Streamlit UI for Tourism Package Prediction\n",
    "st.title(\"Tourism Package Purchase Prediction App\")\n",
    "st.write(\"The Tourism Package Purchase Prediction App is an internal tool for travel company staff that predicts whether customers are likely to purchase the Wellness Tourism Package based on their details.\")\n",
    "st.write(\"Kindly enter the customer details to check whether they are likely to purchase the package.\")\n",
    "\n",
    "# Collect user input\n",
    "Age = st.number_input(\"Age (customer's age in years)\", min_value=18, max_value=100, value=35)\n",
    "TypeofContact = st.selectbox(\"Type of Contact (how the customer was contacted)\", [\"Company Invited\", \"Self Enquiry\"])\n",
    "CityTier = st.selectbox(\"City Tier (city category based on development)\", [1, 2, 3])\n",
    "DurationOfPitch = st.number_input(\"Duration of Pitch (in minutes)\", min_value=0.0, max_value=60.0, value=15.0)\n",
    "Occupation = st.selectbox(\"Occupation (customer's occupation)\", [\"Salaried\", \"Small Business\", \"Large Business\", \"Free Lancer\"])\n",
    "Gender = st.selectbox(\"Gender (customer's gender)\", [\"Male\", \"Female\"])\n",
    "NumberOfPersonVisiting = st.number_input(\"Number of Persons Visiting\", min_value=1, max_value=10, value=2)\n",
    "NumberOfFollowups = st.number_input(\"Number of Follow-ups\", min_value=0.0, max_value=10.0, value=3.0)\n",
    "ProductPitched = st.selectbox(\"Product Pitched (type of product pitched)\", [\"Basic\", \"Standard\", \"Deluxe\", \"Super Deluxe\", \"King\"])\n",
    "PreferredPropertyStar = st.selectbox(\"Preferred Property Star (preferred hotel rating)\", [3.0, 4.0, 5.0])\n",
    "MaritalStatus = st.selectbox(\"Marital Status (customer's marital status)\", [\"Single\", \"Married\", \"Divorced\", \"Unmarried\"])\n",
    "NumberOfTrips = st.number_input(\"Number of Trips (average trips per year)\", min_value=0.0, max_value=20.0, value=2.0)\n",
    "Passport = st.selectbox(\"Has Passport?\", [\"Yes\", \"No\"])\n",
    "PitchSatisfactionScore = st.selectbox(\"Pitch Satisfaction Score\", [1, 2, 3, 4, 5])\n",
    "OwnCar = st.selectbox(\"Owns Car?\", [\"Yes\", \"No\"])\n",
    "NumberOfChildrenVisiting = st.number_input(\"Number of Children Visiting (below age 5)\", min_value=0, max_value=5, value=0)\n",
    "Designation = st.selectbox(\"Designation (customer's designation)\", [\"Executive\", \"Manager\", \"Senior Manager\", \"AVP\", \"VP\"])\n",
    "MonthlyIncome = st.number_input(\"Monthly Income (gross monthly income)\", min_value=0.0, value=20000.0)\n",
    "\n",
    "# Encoding mappings (based on training data)\n",
    "type_of_contact_map = {'Company Invited': 0, 'Self Enquiry': 1}\n",
    "occupation_map = {'Salaried': 0, 'Small Business': 1, 'Large Business': 2, 'Free Lancer': 3}\n",
    "gender_map = {'Male': 0, 'Female': 1}\n",
    "product_pitched_map = {'Basic': 0, 'Standard': 1, 'Deluxe': 2, 'Super Deluxe': 3, 'King': 4}\n",
    "marital_status_map = {'Single': 0, 'Married': 1, 'Divorced': 2, 'Unmarried': 3}\n",
    "designation_map = {'Executive': 0, 'Manager': 1, 'Senior Manager': 2, 'AVP': 3, 'VP': 4}\n",
    "\n",
    "# Convert categorical inputs to match model training\n",
    "input_data = pd.DataFrame([{\n",
    "    'Age': Age,\n",
    "    'TypeofContact': type_of_contact_map[TypeofContact],\n",
    "    'CityTier': CityTier,\n",
    "    'DurationOfPitch': DurationOfPitch,\n",
    "    'Occupation': occupation_map[Occupation],\n",
    "    'Gender': gender_map[Gender],\n",
    "    'NumberOfPersonVisiting': NumberOfPersonVisiting,\n",
    "    'NumberOfFollowups': NumberOfFollowups,\n",
    "    'ProductPitched': product_pitched_map[ProductPitched],\n",
    "    'PreferredPropertyStar': PreferredPropertyStar,\n",
    "    'MaritalStatus': marital_status_map[MaritalStatus],\n",
    "    'NumberOfTrips': NumberOfTrips,\n",
    "    'Passport': 1 if Passport == \"Yes\" else 0,\n",
    "    'PitchSatisfactionScore': PitchSatisfactionScore,\n",
    "    'OwnCar': 1 if OwnCar == \"Yes\" else 0,\n",
    "    'NumberOfChildrenVisiting': NumberOfChildrenVisiting,\n",
    "    'Designation': designation_map[Designation],\n",
    "    'MonthlyIncome': MonthlyIncome\n",
    "}])\n",
    "\n",
    "# Predict button\n",
    "if st.button(\"Predict\"):\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    result = \"purchase the package\" if prediction == 1 else \"not purchase the package\"\n",
    "    st.write(f\"Based on the information provided, the customer is likely to {result}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/deployment/requirements.txt\n",
    "\n",
    "pandas==2.2.2\n",
    "huggingface_hub==0.32.6\n",
    "streamlit==1.43.2\n",
    "joblib==1.5.1\n",
    "scikit-learn==1.6.0\n",
    "xgboost==2.1.4\n",
    "mlflow==3.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tourism_project/hosting\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/hosting/hosting.py\n",
    "\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "api.upload_folder(\n",
    "    folder_path=\"tourism_project/deployment\",     # the local folder containing your files\n",
    "    repo_id=\"<-----Hugging Face User ID ----->/tourism-package-prediction\",          # the target repo\n",
    "    repo_type=\"space\",                      # dataset, model, or space\n",
    "    path_in_repo=\"\",                          # optional: subfolder path inside the repo\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Automate MLOps Pipeline with GitHub Action Workflows using CI/CD\n",
    "## Actions Workflow YAML File\n",
    "* A YAML file is a simple, human-readable file used to store configuration settings.\n",
    "\n",
    "* YAML stands for Yet Another Markup Language or YAML Ain't Markup Language (a recursive acronym).\n",
    "\n",
    "* It uses indentation (spaces) to show structure, like folders inside folders.\n",
    "\n",
    "* Each line contains a key and a value, making it easy to organize data.\n",
    "\n",
    "* YAML is often used in automation tools, cloud setups, and app settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the YAML file we'd need for our use case.\n",
    "```\n",
    "\n",
    "name: Tourism MLOps pipeline\n",
    "\n",
    "\n",
    "\n",
    "on:\n",
    "\n",
    "  push:\n",
    "\n",
    "    branches:\n",
    "\n",
    "      - main  # Automatically triggers on push to the main branch\n",
    "\n",
    "jobs:\n",
    "\n",
    "  register-dataset:\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "\n",
    "      - uses: actions/checkout@v3\n",
    "\n",
    "      - name: Install Dependencies\n",
    "\n",
    "        run: pip install -r tourism_project/requirements.txt\n",
    "\n",
    "      - name: Upload Dataset to Hugging Face Hub\n",
    "\n",
    "        env:\n",
    "\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "\n",
    "        run: python tourism_project/model_building/data_register.py\n",
    "\n",
    "\n",
    "\n",
    "  data-prep:\n",
    "\n",
    "    needs: register-dataset\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "\n",
    "      - uses: actions/checkout@v3\n",
    "\n",
    "      - name: Install Dependencies\n",
    "\n",
    "        run: pip install -r tourism_project/requirements.txt\n",
    "\n",
    "      - name: Run Data Preparation\n",
    "\n",
    "        env:\n",
    "\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "\n",
    "        run: python tourism_project/model_building/prep.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  model-traning:\n",
    "\n",
    "    needs: data-prep\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    steps:\n",
    "\n",
    "      - uses: actions/checkout@v3\n",
    "\n",
    "      - name: Install Dependencies\n",
    "\n",
    "        run: pip install -r tourism_project/requirements.txt\n",
    "\n",
    "      - name: Start MLflow Server\n",
    "\n",
    "        run: |\n",
    "\n",
    "          nohup mlflow ui --host 0.0.0.0 --port 5000 &  # Run MLflow UI in the background\n",
    "\n",
    "          sleep 5  # Wait for a moment to let the server start\n",
    "\n",
    "      - name: Model Building\n",
    "\n",
    "        env:\n",
    "\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "\n",
    "        run: python tourism_project/model_building/train.py\n",
    "\n",
    "\n",
    "\n",
    "  deploy-hosting:\n",
    "\n",
    "    runs-on: ubuntu-latest\n",
    "\n",
    "    needs: [model-traning,data-prep,register-dataset]\n",
    "\n",
    "    steps:\n",
    "\n",
    "      - uses: actions/checkout@v3\n",
    "\n",
    "      - name: Install Dependencies\n",
    "\n",
    "        run: pip install -r tourism_project/requirements.txt\n",
    "\n",
    "      - name: Push files to Frontend Hugging Face Space\n",
    "\n",
    "        env:\n",
    "\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "\n",
    "        run: python tourism_project/hosting/hosting.py\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "**Note:** To use this YAML file for our use case, we need to\n",
    "\n",
    "\n",
    "\n",
    "1. Go to the GitHub repository for the project\n",
    "\n",
    "2. Create a folder named ***.github/workflows/***\n",
    "\n",
    "3. In the above folder, create a file named ***pipeline.yml***\n",
    "\n",
    "4. Copy and paste the above content for the YAML file into the ***pipeline.yml*** file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements file for the Github Actions Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tourism_project/requirements.txt\n",
    "\n",
    "huggingface_hub==0.32.6\n",
    "datasets==3.6.0\n",
    "pandas==2.2.2\n",
    "scikit-learn==1.6.0\n",
    "xgboost==2.1.4\n",
    "mlflow==3.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Authentication and Push Files\n",
    "* Before moving forward, we need to generate a secret token to push files directly from Colab to the GitHub repository.\n",
    "\n",
    "* Please follow the below instructions to create the GitHub token:\n",
    "\n",
    "    - Open your GitHub profile.\n",
    "\n",
    "    - Click on ***Settings***.\n",
    "\n",
    "    - Go to ***Developer Settings***.\n",
    "\n",
    "    - Expand the ***Personal access tokens*** section and select ***Tokens (classic)***.\n",
    "\n",
    "    - Click ***Generate new token***, then choose ***Generate new token (classic)***.\n",
    "\n",
    "    - Add a note and select all required scopes.\n",
    "\n",
    "    - Click ***Generate token***.\n",
    "\n",
    "    - Copy the generated token and store it safely in a notepad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Git\n",
    "!apt-get install git\n",
    "\n",
    "# Set your Git identity (replace with your details)\n",
    "!git config --global user.email \"<-----GitHub email address----->\"\n",
    "!git config --global user.name \"<-----GitHub username----->\"\n",
    "\n",
    "# Clone your GitHub repository\n",
    "!git clone https://github.com/<-----GitHub username----->/<-----GitHub repo name----->.git\n",
    "\n",
    "# Move your folder to the repository directory\n",
    "!mv /content/tourism_project/ /content/<-----GitHub repo name----->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the cloned repository\n",
    "%cd <-----GitHub repo name----->/\n",
    "\n",
    "# Add the new folder to Git\n",
    "!git add .\n",
    "\n",
    "# Commit the changes\n",
    "!git commit -m \"first commit\"\n",
    "\n",
    "# Push to GitHub (you'll need your GitHub credentials; use a personal access token if 2FA enabled)\n",
    "!git push https://<-----GitHub username----->:<-----GitHub token ----->@github.com/<-----GitHub username----->/<-----GitHub repo name----->.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Evaluation\n",
    "- GitHub (link to repository, screenshot of folder structure and executed workflow)\n",
    "\n",
    "- Streamlit on Hugging Face (link to HF space, screenshot of Streamlit app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6 color=\"navyblue\">Power Ahead!</font>\n",
    "\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
